from pydantic import BaseModel, Field
from typing import List, Dict, Optional
#comments: schema is like format of task

class Task(BaseModel):
    """
    Task used in training.
    """
    task_id: str = Field(default=...)

    env_type: str = Field(default="appworld")

    # whether this task is open query. open query has no clear stop condition.
    open_query: bool = Field() # FIXME debug, check if every instance handles this new attr. default False.

    metadata: dict = Field(default_factory=dict)

    # query. if set, the original query will be replaced by this before training.
    query: Optional[str] = Field(default=None)
    # #Query = 考试题目类似于任务描述
    # Reference Solution = 标准答案。好几步的实现任务的方案
    # synthetic ground truth generated by TaskManager in stage 2, used in llm judge as reference trajectory
    # 对应论文中的Reference Solution Extraction
    ground_truth:Optional[str] = Field(default=None,description="ground truth")
    # ground_truth 可以是字符串或None，默认是None，代表任务可能没有参考答案
    #Field 是设置默认值的增强版方式，它不仅能设置默认值，还能添加验证规则、文档说明等，让代码更健壮。
    evaluator: str = Field(default="env")
#Field = 字段的"配置说明书"，告诉系统这个字段的默认值是什么、能接受什么样的数据。

class TaskObjective(BaseModel):
    """
    Task used in task exploration and extraction only.

    It includes the custom ground_truth and reward, which may be merged to Task and used in training in future.
    """

    task:Task=Field(...,description="task")
    confidence:Optional[float]=Field(None,description="confidence")
    reward:Optional[float]=Field(None,description="reward")

    @property
    def objective(self):
        return self.task.query

    @property
    def ground_truth(self):
        return self.task.ground_truth

    @ground_truth.setter
    def ground_truth(self,v):
        self.task.ground_truth=v
